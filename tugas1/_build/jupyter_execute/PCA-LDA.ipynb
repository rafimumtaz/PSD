{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb934cd",
   "metadata": {},
   "source": [
    "# PCA-LDA DATASET ECOLI\n",
    "\n",
    "Notebook ini bertujuan untuk menganalisis dataset Ecoli yang tersimpan di database MySQL. Dataset Ecoli berisi beberapa fitur numerik yang menggambarkan karakteristik protein, dan sebuah label kelas yang menunjukkan lokasi subselular protein tersebut (misalnya cp, im, om, dll).\n",
    "\n",
    "Analisis ini menggunakan dua metode reduksi dimensi:\n",
    "\n",
    "Principal Component Analysis (PCA)\n",
    "\n",
    "Linear Discriminant Analysis (LDA)\n",
    "\n",
    "Keduanya akan digunakan untuk memproyeksikan data berdimensi tinggi (7 fitur) ke dalam ruang dua dimensi, sehingga distribusi data antar kelas dapat divisualisasikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89f83aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# === KONEKSI KE MYSQL ===\n",
    "engine = create_engine(\"mysql+pymysql://root:@localhost/ecoli\")\n",
    "\n",
    "# === AMBIL DATA ===\n",
    "df = pd.read_sql(\"SELECT * FROM ecoli\", engine)\n",
    "print(df.head())\n",
    "\n",
    "# === PISAHKAN FITUR DAN LABEL ===\n",
    "X = df[[\"feature1\",\"feature2\",\"feature3\",\"feature4\",\"feature5\",\"feature6\",\"feature7\"]].values\n",
    "y_raw = df[\"class_label\"].values\n",
    "\n",
    "# encode label\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "target_names = le.classes_\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# === Distribusi kelas sebelum balancing ===\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dist_before = dict(zip(le.classes_, counts))\n",
    "print(\"Distribusi kelas sebelum balancing:\", dist_before)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(dist_before.keys(), dist_before.values(), color=\"skyblue\")\n",
    "for i, val in enumerate(dist_before.values()):\n",
    "    plt.text(i, val+2, str(val), ha='center')\n",
    "plt.title(\"Distribusi Kelas Sebelum Balancing\")\n",
    "plt.xlabel(\"Kelas\")\n",
    "plt.ylabel(\"Jumlah Data\")\n",
    "plt.show()\n",
    "\n",
    "# === PCA DATA ASLI ===\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "colors = [\"navy\",\"turquoise\",\"darkorange\",\"green\",\"red\",\"purple\",\"brown\",\"gray\"]\n",
    "for color, i, target_name in zip(colors, range(len(target_names)), target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=0.8, label=target_name)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"PCA of Original Ecoli dataset\")\n",
    "plt.show()\n",
    "\n",
    "# === SMOTE untuk penyeimbangan data ===\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Distribusi kelas sesudah balancing\n",
    "unique_res, counts_res = np.unique(y_res, return_counts=True)\n",
    "dist_after = dict(zip(le.inverse_transform(unique_res), counts_res))\n",
    "print(\"Distribusi kelas sesudah balancing:\", dist_after)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(dist_after.keys(), dist_after.values(), color=\"lightgreen\")\n",
    "for i, val in enumerate(dist_after.values()):\n",
    "    plt.text(i, val+2, str(val), ha='center')\n",
    "plt.title(\"Distribusi Kelas Sesudah Balancing (SMOTE)\")\n",
    "plt.xlabel(\"Kelas\")\n",
    "plt.ylabel(\"Jumlah Data\")\n",
    "plt.show()\n",
    "\n",
    "# === PCA DATA BALANCED ===\n",
    "X_r_bal = pca.fit(X_res).transform(X_res)\n",
    "is_synthetic = np.array([False]*len(y) + [True]*(len(X_res)-len(y)))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for color, i, target_name in zip(colors, range(len(target_names)), target_names):\n",
    "    plt.scatter(\n",
    "        X_r_bal[(y_res == i) & (is_synthetic == False), 0],\n",
    "        X_r_bal[(y_res == i) & (is_synthetic == False), 1],\n",
    "        color=color, alpha=0.6, label=f\"{target_name} (original)\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        X_r_bal[(y_res == i) & (is_synthetic == True), 0],\n",
    "        X_r_bal[(y_res == i) & (is_synthetic == True), 1],\n",
    "        color=color, alpha=0.6, marker=\"x\", label=f\"{target_name} (synthetic)\"\n",
    "    )\n",
    "plt.legend(loc=\"best\", fontsize=8)\n",
    "plt.title(\"PCA of Balanced Ecoli dataset (SMOTE)\")\n",
    "plt.show()\n",
    "\n",
    "# === Fungsi evaluasi model ===\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n=== Evaluasi {name} ===\")\n",
    "    print(\"Akurasi:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\",\n",
    "                xticklabels=target_names, yticklabels=target_names, cmap=\"coolwarm\")\n",
    "    plt.title(f\"Confusion Matrix {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "# === KLASIFIKASI SEBELUM BALANCING ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "evaluate_model(\"Naive Bayes (Sebelum Balancing)\", GaussianNB(), X_train, X_test, y_train, y_test)\n",
    "evaluate_model(\"Random Forest (Sebelum Balancing)\", RandomForestClassifier(random_state=42, n_estimators=100), X_train, X_test, y_train, y_test)\n",
    "evaluate_model(\"Bagging (Sebelum Balancing)\", BaggingClassifier(random_state=42, n_estimators=100), X_train, X_test, y_train, y_test)\n",
    "\n",
    "# === KLASIFIKASI SESUDAH BALANCING ===\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X_res, y_res, test_size=0.3, random_state=42, stratify=y_res)\n",
    "\n",
    "evaluate_model(\"Naive Bayes (Sesudah Balancing)\", GaussianNB(), X_train_res, X_test_res, y_train_res, y_test_res)\n",
    "evaluate_model(\"Random Forest (Sesudah Balancing)\", RandomForestClassifier(random_state=42, n_estimators=100), X_train_res, X_test_res, y_train_res, y_test_res)\n",
    "evaluate_model(\"Bagging (Sesudah Balancing)\", BaggingClassifier(random_state=42, n_estimators=100), X_train_res, X_test_res, y_train_res, y_test_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71ddeb",
   "metadata": {},
   "source": [
    "Dalam proyek ini, dataset Ecoli yang digunakan memiliki distribusi kelas yang sangat tidak seimbang. Sebagai contoh, beberapa kelas minoritas ekstrem hanya memiliki 2â€“5 sampel, sedangkan kelas mayoritas memiliki lebih dari 100 sampel:\n",
    "\n",
    "{'cp': 143, 'im': 77, 'imL': 2, 'imS': 2, 'imU': 35, 'om': 20, 'omL': 5, 'pp': 52}\n",
    "\n",
    "Awalnya, penyeimbangan data dicoba menggunakan ADASYN, karena metode ini dapat membuat sampel synthetic yang fokus pada titik-titik minoritas yang sulit dipelajari (hard-to-learn). Namun, ADASYN memerlukan jumlah sampel minoritas minimal 3 untuk mencari tetangga dari kelas mayoritas.\n",
    "\n",
    "Dalam dataset ini, kelas imL dan imS hanya memiliki 2 sampel, sehingga ADASYN gagal mengeksekusi proses penyeimbangan dan menghasilkan error:\n",
    "\n",
    "RuntimeError: Not any neighbours belong to the majority class...\n",
    "\n",
    "Untuk mengatasi hal ini, dipilih SMOTE (Synthetic Minority Over-sampling Technique) sebagai metode penyeimbangan. SMOTE tetap bisa bekerja untuk kelas minoritas yang sangat kecil dengan cara:\n",
    "\n",
    "Membuat sampel synthetic dengan menginterpolasi antara titik minoritas dan tetangga terdekatnya.\n",
    "\n",
    "Memungkinkan pengaturan k_neighbors secara manual, sehingga dapat disesuaikan dengan jumlah sampel minoritas (dalam kasus ini, k_neighbors=1).\n",
    "\n",
    "Dengan SMOTE, semua kelas minoritas, termasuk yang memiliki sangat sedikit sampel, dapat dibuatkan sampel synthetic dengan aman tanpa error, sehingga dataset menjadi lebih seimbang dan siap untuk analisis atau pemodelan berikutnya."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}