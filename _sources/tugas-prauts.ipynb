{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a57717e",
   "metadata": {},
   "source": [
    "# Tugas pra-UTS PSD\n",
    "\n",
    "## Analisis Data E. coli Menggunakan KNIME, PostgreSQL, dan Python untuk Prediksi Klasifikasi Protein\n",
    "\n",
    "### Oleh : Hajjid Rafi Mumtaz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f9350",
   "metadata": {},
   "source": [
    "## 1. Instalasi teknologi yang diperlukan.\n",
    "\n",
    "- KNIME Analytics Platform: Alat utama untuk membangun alur kerja visual.\n",
    "- Miniforge (Conda): Untuk manajemen environment Python yang terisolasi.\n",
    "- PostgreSQL: Database tempat data disimpan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae80513",
   "metadata": {},
   "source": [
    "#### 1.1 Membuat dan Mengkonfigurasi Environment Conda\n",
    "\n",
    "Kita memerlukan environment Python khusus yang berisi semua library yang dibutuhkan oleh KNIME.\n",
    "\n",
    "1. Buka Miniforge Prompt.\n",
    "\n",
    "2. Buat environment baru bernama tugaspsd (atau nama lain yang sesuai) dengan perintah:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create --name tugaspsd python=3.9 pandas psycopg2-binary scikit-learn matplotlib -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed9772",
   "metadata": {},
   "source": [
    "3. Aktifkan environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ecd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate tugaspsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde270f",
   "metadata": {},
   "source": [
    "4. Install library imbalanced-learn dari channel conda-forge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge imbalanced-learn -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee70f97",
   "metadata": {},
   "source": [
    "#### 1.2 Mengintegrasikan Python dengan KNIME\n",
    "\n",
    "Langkah krusial adalah menghubungkan KNIME dengan environment Conda yang baru dibuat.\n",
    "\n",
    "1. Buka KNIME, lalu navigasi ke File > Preferences.\n",
    "\n",
    "2. Pilih KNIME > Python Integration.\n",
    "\n",
    "3. Pilih opsi Conda dan pilih environment tugaspsd dari daftar. Jika tidak terdeteksi, pilih Manual dan arahkan ke file python.exe di dalam folder environment Anda (contoh: D:\\miniforge3\\envs\\tugaspsd\\python.exe).\n",
    "\n",
    "4. Klik Apply and Close.\n",
    "\n",
    "![install extension python pada KNIME](Screenshot_45.png)\n",
    "![integrasi python pada KNIME](Screenshot_51.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68cfa2",
   "metadata": {},
   "source": [
    "## 2. Membangun Alur Kerja (Workflow) di KNIME\n",
    "\n",
    "### 2.1 Koneksi ke Database PostgreSQL.\n",
    "\n",
    "Dua node utama digunakan untuk mengambil data:\n",
    "\n",
    "1. PostgreSQL Connector: Node ini dikonfigurasi dengan kredensial database (host, port, nama database, username, dan password) untuk membuat koneksi.\n",
    "\n",
    "2. DB Table Selector: Node ini menerima koneksi dari node sebelumnya dan digunakan untuk memilih tabel yang akan digunakan.\n",
    "\n",
    "3. DB Reader: Node ini menerima koneksi dari node sebelumnya dan mengeksekusi query SQL sederhana untuk mengambil seluruh data dari tabel ecoli. Contoh query: SELECT * FROM ecoli;\n",
    "\n",
    "jangan lupa untuk menginstall dan mengintegrasikan Driver PostgreSQL sebelum melakukan koneksi. \n",
    "\n",
    "- langkah integrasi driver\n",
    "![integrasi Driver PostgreSQL](Screenshot_46.png)\n",
    "![integrasi Driver PostgreSQL](Screenshot_47.png)\n",
    "- workflow/nodes yang digunakan\n",
    "![workflow](Screenshot_44.png)\n",
    "- koneksi postgre connector\n",
    "![integrasi Driver PostgreSQL](Screenshot_48.png)\n",
    "- table selector\n",
    "![integrasi Driver PostgreSQL](Screenshot_49.png)\n",
    "- Hasil yang ditampilkan oleh DB Reader\n",
    "![integrasi Driver PostgreSQL](Screenshot_50.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6048cf",
   "metadata": {},
   "source": [
    "### 2.2. Eksekusi Script Python untuk Pemrosesan Data\n",
    "\n",
    "Inti dari analisis ini berada di dalam satu node Python Script. Node ini menerima tabel data dari DB Query Reader sebagai input dan menjalankan serangkaian tugas kompleks:\n",
    "\n",
    "1. Penanganan missing value: Mengisi nilai numerik yang kosong dengan median.\n",
    "\n",
    "2. Deteksi Outlier: Menggunakan metode IQR untuk mengidentifikasi dan memisahkan data outlier.\n",
    "\n",
    "3. Pemisahan Fitur & Target: Memisahkan kolom fitur (prediktor) dari kolom target (class_label).\n",
    "\n",
    "4. Penyeimbangan Kelas/Data Balancing (SMOTE): Mengatasi masalah kelas tidak seimbang dengan membuat sampel sintetis untuk kelas minoritas.\n",
    "\n",
    "untuk script python terlampir dibawa ini :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# === 1. Load dataset dari KNIME dan buat salinannya ===\n",
    "dataset = input_table_1.copy()\n",
    "\n",
    "# === 2. Cek dan tangani missing values ===\n",
    "print(\"Jumlah missing values sebelum penanganan:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "dataset = dataset.fillna(dataset.median(numeric_only=True))\n",
    "\n",
    "print(\"\\nJumlah missing values sesudah penanganan:\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "# === 3. Deteksi dan hapus outlier menggunakan metode IQR ===\n",
    "numerical_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "Q1 = dataset[numerical_cols].quantile(0.25)\n",
    "Q3 = dataset[numerical_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "batas_bawah = Q1 - 1.5 * IQR\n",
    "batas_atas = Q3 + 1.5 * IQR\n",
    "\n",
    "is_outlier = ((dataset[numerical_cols] < batas_bawah) | (dataset[numerical_cols] > batas_atas)).any(axis=1)\n",
    "\n",
    "outliers_detected = dataset[is_outlier]\n",
    "print(f\"\\nJumlah outlier yang terdeteksi: {len(outliers_detected)}\")\n",
    "\n",
    "dataset_no_outlier = dataset[~is_outlier]\n",
    "\n",
    "print(f\"Jumlah data sebelum hapus outlier: {len(dataset)}\")\n",
    "print(f\"Jumlah data sesudah hapus outlier: {len(dataset_no_outlier)}\")\n",
    "\n",
    "\n",
    "# === 4. Pisahkan fitur (X) dan target (y) ===\n",
    "target_col = 'class_label'\n",
    "X = dataset_no_outlier.drop(columns=[target_col, 'id_protein'])\n",
    "y = dataset_no_outlier[target_col]\n",
    "\n",
    "# === 5. Balancing dataset menggunakan SMOTE ===\n",
    "# Cek jika ada kelas dengan sampel < 2, yang membuat SMOTE gagal\n",
    "min_class_count = y.value_counts().min()\n",
    "if min_class_count < 2:\n",
    "    X_res, y_res = X, y\n",
    "    print(\"\\nSMOTE dilewati karena ada kelas dengan sampel < 2.\")\n",
    "else:\n",
    "    smote = SMOTE(random_state=42, k_neighbors=min_class_count - 1)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print(f\"\\nJumlah data sebelum SMOTE: {y.value_counts().to_dict()}\")\n",
    "print(f\"Jumlah data sesudah SMOTE: {pd.Series(y_res).value_counts().to_dict()}\")\n",
    "\n",
    "# === 6. Split data (train dan test) ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 7. Standarisasi fitur ===\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# === 8. Naive Bayes (GaussianNB) ===\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# === 9. Prediksi ===\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# === 10. Hasil prediksi ===\n",
    "hasil = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nContoh hasil prediksi:\")\n",
    "print(hasil.head())\n",
    "\n",
    "# === 11. Visualisasi distribusi kelas setelah SMOTE ===\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "pd.Series(y_res).value_counts().plot(kind='bar', ax=ax, color='skyblue')\n",
    "ax.set_title(\"Distribusi Kelas Setelah SMOTE\")\n",
    "ax.set_xlabel(\"Kelas\")\n",
    "ax.set_ylabel(\"Jumlah Data\")\n",
    "\n",
    "# === 12. Output ke KNIME ===\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "output_table_1 = hasil                   \n",
    "output_table_2 = dataset_no_outlier     \n",
    "output_table_3 = outliers_detected       \n",
    "output_image_1 = fig       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28804bf",
   "metadata": {},
   "source": [
    "## 3. Analisis Hasil dan Output \n",
    "\n",
    "### 3.1 Output dari Script Python.\n",
    "\n",
    "Node Python Script dikonfigurasi untuk menghasilkan beberapa output:\n",
    "\n",
    "- Tabel Hasil Prediksi: Tabel perbandingan antara kelas aktual (Actual) dan kelas yang diprediksi (Predicted).\n",
    "\n",
    "- Tabel Data Bersih: Dataset setelah outlier dihilangkan.\n",
    "\n",
    "- Tabel Outlier: Daftar baris data yang terdeteksi sebagai outlier.\n",
    "\n",
    "\n",
    "OUTPUT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jumlah missing values sebelum penanganan:\n",
    "\n",
    "id_protein     0\n",
    "feature1       0\n",
    "feature2       0\n",
    "feature3       0\n",
    "feature4       0\n",
    "feature5       0\n",
    "feature6       0\n",
    "feature7       0\n",
    "class_label    0\n",
    "dtype: int64\n",
    "Jumlah missing values sesudah penanganan:\n",
    "id_protein     0\n",
    "feature1       0\n",
    "feature2       0\n",
    "feature3       0\n",
    "feature4       0\n",
    "feature5       0\n",
    "feature6       0\n",
    "feature7       0\n",
    "class_label    0\n",
    "dtype: int64\n",
    "Jumlah outlier yang terdeteksi: 0\n",
    "Jumlah data sebelum hapus outlier: 336\n",
    "Jumlah data sesudah hapus outlier: 336\n",
    "Jumlah data sebelum SMOTE: {'cp': 143, 'im': 77, 'pp': 52, 'imU': 35, 'om': 20, 'omL': 5, 'imS': 2, 'imL': 2}\n",
    "Jumlah data sesudah SMOTE: {'cp': 143, 'im': 143, 'imS': 143, 'imL': 143, 'imU': 143, 'om': 143, 'omL': 143, 'pp': 143}\n",
    "Contoh hasil prediksi:\n",
    "  Actual Predicted\n",
    "0     im        pp\n",
    "1     om        pp\n",
    "2    imL       imL\n",
    "3    imS       imS\n",
    "4     pp        pp\n",
    "\n",
    "Dari hasil yang didapat, terlihat bahwa teknik SMOTE berhasil menyeimbangkan distribusi kelas, yang merupakan langkah penting untuk mencegah bias pada model machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
